{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "protein.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taguka/atlas/blob/master/protein.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2KF_12MnNKe9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "QWX5PNhEIHdq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "!pip3 install https://download.pytorch.org/whl/cu80/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip install torchvision\n",
        "!pip install pretrainedmodels\n",
        "!pip install attrdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "68X5Ll2yIhN0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZhtovK8hIkjq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install kaggle\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "\n",
        "!kaggle competitions download -c human-protein-atlas-image-classification\n",
        "!unzip -qq train.zip -d train | awk 'BEGIN {ORS=\" \"} {if(NR%500==0) print \".\"}'\n",
        "!unzip -qq test.zip -d test | awk 'BEGIN {ORS=\" \"} {if(NR%500==0) print \".\"}'\n",
        "!rm test.zip\n",
        "!rm train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jtxkjpHYPUDm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Config"
      ]
    },
    {
      "metadata": {
        "id": "CZL9PNqtPV8Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from attrdict import AttrDict\n",
        "\n",
        "config = AttrDict()\n",
        "config.output_path = 'gdrive/My Drive/protein/output/'\n",
        "config.data_path = '/content'\n",
        "config.submission_path = 'gdrive/My Drive/protein/submissions/'\n",
        "config.target_file = 'gdrive/My Drive/protein/labels.csv'\n",
        "config.checkpoint = None\n",
        "config.num_classes=28\n",
        "config.num_channels=3\n",
        "config.model = 'resnet50'\n",
        "config.opt = 'sgd'\n",
        "config.loss = 'bce'\n",
        "config.fold=0\n",
        "config.batch_size = 8\n",
        "config.img_size = 512\n",
        "config.epochs=50\n",
        "config.decay_epochs=15\n",
        "config.ft_epochs=0\n",
        "config.ft_opt='sgd'\n",
        "config.ft_lr='sgd'\n",
        "config.dropout=0.1\n",
        "config.lr = 0.0010\n",
        "config.momentum=0.9\n",
        "config.weight_decay=0.0005\n",
        "config.seed=10\n",
        "config.log_interval=1000\n",
        "config.print_freq=10\n",
        "config.no_cuda=False\n",
        "config.external_data = True\n",
        "config.use_sampler = True\n",
        "config.exp='stage_1'\n",
        "\n",
        "config.save_batches=False\n",
        "config.class_weights=True\n",
        "config.num_epochs = [1, 8, 8]\n",
        "config.cycles_len = [0, 2, 4]\n",
        "config.lr_divs = [0, 4, 12]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pvb2HC1PKPq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import Sampler\n",
        "class WeightedRandomOverSampler(Sampler):\n",
        "    #Over-samples elements from [0,..,len(weights)-1] factor number of times.\n",
        "    #Each element is sample at least once, the remaining over-sampling is determined\n",
        "    #by the weights.\n",
        "    #Arguments:\n",
        "    #    weights (list) : a list of weights, not necessary summing up to one\n",
        "    #    factor (float) : the oversampling factor (>= 1.0)\n",
        "   \n",
        "\n",
        "    def __init__(self, weights, factor=2.):\n",
        "        self.weights = torch.DoubleTensor(weights)\n",
        "        assert factor >= 1.\n",
        "        self.num_samples = int(len(self.weights) * factor)\n",
        "\n",
        "    def __iter__(self):\n",
        "        base_samples = torch.arange(0, len(self.weights)).long()\n",
        "        remaining = self.num_samples - len(self.weights)\n",
        "        over_samples = torch.multinomial(self.weights, remaining, True)\n",
        "        samples = torch.cat((base_samples, over_samples), dim=0)\n",
        "        print('num samples', len(samples))\n",
        "        return (samples[i] for i in torch.randperm(len(samples)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-93mt_IOPJay",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "import albumentations as album\n",
        "def get_transforms(image_size: int) -> Tuple[album.Compose, album.Compose, album.Compose]:\n",
        "    transforms_train = album.Compose([\n",
        "        album.Resize(image_size, image_size, interpolation=Image.BICUBIC),\n",
        "        album.Rotate(interpolation=Image.BICUBIC),\n",
        "        album.RandomRotate90(),\n",
        "        album.HorizontalFlip(),\n",
        "        album.RandomBrightnessContrast(),\n",
        "        album.Normalize([0.08069, 0.05258, 0.05487], [0.13704, 0.10145, 0.15313])\n",
        "    ])\n",
        "\n",
        "    transforms_test = album.Compose([\n",
        "        album.Resize(image_size, image_size, interpolation=Image.BICUBIC),\n",
        "        album.Normalize([0.08069, 0.05258, 0.05487], [0.13704, 0.10145, 0.15313])\n",
        "    ])\n",
        "\n",
        "    transforms_test_aug = album.Compose([\n",
        "        album.Resize(image_size, image_size, interpolation=Image.BICUBIC),\n",
        "        album.Rotate(interpolation=Image.BICUBIC),\n",
        "        album.RandomRotate90(),\n",
        "        album.HorizontalFlip(),\n",
        "        album.Normalize([0.08069, 0.05258, 0.05487], [0.13704, 0.10145, 0.15313])\n",
        "    ])\n",
        "\n",
        "    return transforms_train, transforms_test, transforms_test_aug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AwUDQDkEOXpD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Opt"
      ]
    },
    {
      "metadata": {
        "id": "9M75n_eNOcpG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Reduce on Plateau Learning Rate Scheduler\n",
        "Taken from pytorch master to use with 0.12 release.\n",
        "\"\"\"\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "\n",
        "class _LRScheduler(object):\n",
        "    def __init__(self, optimizer, last_epoch=-1):\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "        if last_epoch == -1:\n",
        "            for group in optimizer.param_groups:\n",
        "                group.setdefault('initial_lr', group['lr'])\n",
        "        else:\n",
        "            for i, group in enumerate(optimizer.param_groups):\n",
        "                if 'initial_lr' not in group:\n",
        "                    raise KeyError(\"param 'initial_lr' is not specified \"\n",
        "                                   \"in param_groups[{}] when resuming an optimizer\".format(i))\n",
        "        self.base_lrs = list(map(lambda group: group['initial_lr'], optimizer.param_groups))\n",
        "        self.step(last_epoch + 1)\n",
        "        self.last_epoch = last_epoch\n",
        "\n",
        "    def get_lr(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch + 1\n",
        "        self.last_epoch = epoch\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "\n",
        "class ReduceLROnPlateau(object):\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving.\n",
        "    Models often benefit from reducing the learning rate by a factor\n",
        "    of 2-10 once learning stagnates. This scheduler reads a metrics\n",
        "    quantity and if no improvement is seen for a 'patience' number\n",
        "    of epochs, the learning rate is reduced.\n",
        "\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        mode (str): One of `min`, `max`. In `min` mode, lr will\n",
        "            be reduced when the quantity monitored has stopped\n",
        "            decreasing; in `max` mode it will be reduced when the\n",
        "            quantity monitored has stopped increasing. Default: 'min'.\n",
        "        factor (float): Factor by which the learning rate will be\n",
        "            reduced. new_lr = lr * factor. Default: 0.1.\n",
        "        patience (int): Number of epochs with no improvement after\n",
        "            which learning rate will be reduced. Default: 10.\n",
        "        verbose (bool): If True, prints a message to stdout for\n",
        "            each update. Default: False.\n",
        "        threshold (float): Threshold for measuring the new optimum,\n",
        "            to only focus on significant changes. Default: 1e-4.\n",
        "        threshold_mode (str): One of `rel`, `abs`. In `rel` mode,\n",
        "            dynamic_threshold = best * ( 1 + threshold ) in 'max'\n",
        "            mode or best * ( 1 - threshold ) in `min` mode.\n",
        "            In `abs` mode, dynamic_threshold = best + threshold in\n",
        "            `max` mode or best - threshold in `min` mode. Default: 'rel'.\n",
        "        cooldown (int): Number of epochs to wait before resuming\n",
        "            normal operation after lr has been reduced. Default: 0.\n",
        "        min_lr (float or list): A scalar or a list of scalars. A\n",
        "            lower bound on the learning rate of all param groups\n",
        "            or each group respectively. Default: 0.\n",
        "        eps (float): Minimal decay applied to lr. If the difference\n",
        "            between new and old lr is smaller than eps, the update is\n",
        "            ignored. Default: 1e-8.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, mode='min', factor=0.1, patience=10,\n",
        "                 verbose=False, threshold=1e-4, threshold_mode='rel',\n",
        "                 cooldown=0, min_lr=0, eps=1e-8):\n",
        "\n",
        "        if factor >= 1.0:\n",
        "            raise ValueError('Factor should be < 1.0.')\n",
        "        self.factor = factor\n",
        "\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        if isinstance(min_lr, list) or isinstance(min_lr, tuple):\n",
        "            if len(min_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} min_lrs, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(min_lr)))\n",
        "            self.min_lrs = list(min_lr)\n",
        "        else:\n",
        "            self.min_lrs = [min_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.cooldown = cooldown\n",
        "        self.cooldown_counter = 0\n",
        "        self.mode = mode\n",
        "        self.threshold = threshold\n",
        "        self.threshold_mode = threshold_mode\n",
        "        self.best = None\n",
        "        self.num_bad_epochs = None\n",
        "        self.mode_worse = None  # the worse value for the chosen mode\n",
        "        self.is_better = None\n",
        "        self.eps = eps\n",
        "        self.last_epoch = -1\n",
        "        self._init_is_better(mode=mode, threshold=threshold,\n",
        "                             threshold_mode=threshold_mode)\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        \"\"\"Resets num_bad_epochs counter and cooldown counter.\"\"\"\n",
        "        self.best = self.mode_worse\n",
        "        self.cooldown_counter = 0\n",
        "        self.num_bad_epochs = 0\n",
        "\n",
        "    def step(self, metrics, epoch=None):\n",
        "        current = metrics\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch = self.last_epoch + 1\n",
        "        self.last_epoch = epoch\n",
        "\n",
        "        if self.is_better(current, self.best):\n",
        "            self.best = current\n",
        "            self.num_bad_epochs = 0\n",
        "        else:\n",
        "            self.num_bad_epochs += 1\n",
        "\n",
        "        if self.in_cooldown:\n",
        "            self.cooldown_counter -= 1\n",
        "            self.num_bad_epochs = 0  # ignore any bad epochs in cooldown\n",
        "\n",
        "        if self.num_bad_epochs > self.patience:\n",
        "            self._reduce_lr(epoch)\n",
        "            self.cooldown_counter = self.cooldown\n",
        "            self.num_bad_epochs = 0\n",
        "\n",
        "    def _reduce_lr(self, epoch):\n",
        "        for i, param_group in enumerate(self.optimizer.param_groups):\n",
        "            old_lr = float(param_group['lr'])\n",
        "            new_lr = max(old_lr * self.factor, self.min_lrs[i])\n",
        "            if old_lr - new_lr > self.eps:\n",
        "                param_group['lr'] = new_lr\n",
        "                if self.verbose:\n",
        "                    print('Epoch {:5d}: reducing learning rate'\n",
        "                          ' of group {} to {:.4e}.'.format(epoch, i, new_lr))\n",
        "\n",
        "    @property\n",
        "    def in_cooldown(self):\n",
        "        return self.cooldown_counter > 0\n",
        "\n",
        "    def _init_is_better(self, mode, threshold, threshold_mode):\n",
        "        if mode not in {'min', 'max'}:\n",
        "            raise ValueError('mode ' + mode + ' is unknown!')\n",
        "        if threshold_mode not in {'rel', 'abs'}:\n",
        "            raise ValueError('threshold mode ' + mode + ' is unknown!')\n",
        "        if mode == 'min' and threshold_mode == 'rel':\n",
        "            rel_epsilon = 1. - threshold\n",
        "            self.is_better = lambda a, best: a < best * rel_epsilon\n",
        "            self.mode_worse = float('Inf')\n",
        "        elif mode == 'min' and threshold_mode == 'abs':\n",
        "            self.is_better = lambda a, best: a < best - threshold\n",
        "            self.mode_worse = float('Inf')\n",
        "        elif mode == 'max' and threshold_mode == 'rel':\n",
        "            rel_epsilon = threshold + 1.\n",
        "            self.is_better = lambda a, best: a > best * rel_epsilon\n",
        "            self.mode_worse = -float('Inf')\n",
        "        else:  # mode == 'max' and epsilon_mode == 'abs':\n",
        "            self.is_better = lambda a, best: a > best + threshold\n",
        "            self.mode_worse = -float('Inf')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U6VjypULOdWQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Yellowfin Optimizer\n",
        "Sourced from: https://github.com/JianGoForIt/YellowFin_Pytorch (MIT License)\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "# for torch optim sgd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class YFOptimizer(object):\n",
        "  def __init__(self, var_list, lr=0.1, mu=0.0, clip_thresh=None, weight_decay=0.0,\n",
        "    beta=0.999, curv_win_width=20, zero_debias=True, delta_mu=0.0):\n",
        "    '''\n",
        "    clip thresh is the threshold value on ||lr * gradient||\n",
        "    delta_mu can be place holder/variable/python scalar. They are used for additional\n",
        "    momentum in situations such as asynchronous-parallel training. The default is 0.0\n",
        "    for basic usage of the optimizer.\n",
        "    Args:\n",
        "      lr: python scalar. The initial value of learning rate, we use 1.0 in our paper.\n",
        "      mu: python scalar. The initial value of momentum, we use 0.0 in our paper.\n",
        "      clip_thresh: python scalar. The cliping threshold for tf.clip_by_global_norm.\n",
        "        if None, no clipping will be carried out. \n",
        "      beta: python scalar. The smoothing parameter for estimations.\n",
        "      delta_mu: for extensions. Not necessary in the basic use. (TODO)\n",
        "    Other features:\n",
        "      If you want to manually control the learning rates, self.lr_factor is\n",
        "      an interface to the outside, it is an multiplier for the internal learning rate\n",
        "      in YellowFin. It is helpful when you want to do additional hand tuning\n",
        "      or some decaying scheme to the tuned learning rate in YellowFin. \n",
        "      Example on using lr_factor can be found here:\n",
        "      (TODO)\n",
        "    '''\n",
        "    self._lr = lr\n",
        "    self._mu = mu\n",
        "    # we convert var_list from generator to list so that\n",
        "    # it can be used for multiple times\n",
        "    self._var_list = list(var_list)\n",
        "    self._clip_thresh = clip_thresh\n",
        "    self._beta = beta\n",
        "    self._curv_win_width = curv_win_width\n",
        "    self._zero_debias = zero_debias\n",
        "    self._optimizer = torch.optim.SGD(self._var_list, lr=self._lr, \n",
        "      momentum=self._mu, weight_decay=weight_decay)\n",
        "    self._iter = 0\n",
        "    # global states are the statistics\n",
        "    self._global_state = {}\n",
        "\n",
        "    # for decaying learning rate and etc.\n",
        "    self._lr_factor = 1.0\n",
        "    pass\n",
        "\n",
        "\n",
        "  def state_dict(self):\n",
        "    sgd_state_dict = self._optimizer.state_dict()\n",
        "    global_state = self._global_state\n",
        "    lr_factor = self._lr_factor\n",
        "    iter = self._iter\n",
        "    lr = self._lr\n",
        "    mu = self._mu\n",
        "\n",
        "    return {\n",
        "      \"sgd_state_dict\": sgd_state_dict,\n",
        "      \"global_state\": global_state,\n",
        "      \"lr_factor\": lr_factor,\n",
        "      \"iter\": iter,\n",
        "      \"lr\": lr,\n",
        "      \"mu\": mu,\n",
        "    }\n",
        "\n",
        "\n",
        "  def load_state_dict(self, state_dict):\n",
        "    self._optimizer.load_state_dict(state_dict['sgd_state_dict'])\n",
        "    self._global_state = state_dict['global_state']\n",
        "    self._lr_factor = state_dict['lr_factor']\n",
        "    self._iter = state_dict['iter']\n",
        "    self._lr = state_dict['lr']\n",
        "    self._mu = state_dict['mu']\n",
        "\n",
        "\n",
        "  def set_lr_factor(self, factor):\n",
        "    self._lr_factor = factor\n",
        "    return\n",
        "\n",
        "\n",
        "  def get_lr_factor(self):\n",
        "    return self._lr_factor\n",
        "\n",
        "\n",
        "  def zero_grad(self):\n",
        "    self._optimizer.zero_grad()\n",
        "\n",
        "\n",
        "  def zero_debias_factor(self):\n",
        "    return 1.0 - self._beta ** (self._iter + 1)\n",
        "\n",
        "\n",
        "  def curvature_range(self):\n",
        "    global_state = self._global_state\n",
        "    if self._iter == 0:\n",
        "      global_state[\"curv_win\"] = torch.FloatTensor(self._curv_win_width, 1).zero_()\n",
        "    curv_win = global_state[\"curv_win\"]\n",
        "    grad_norm_squared = self._global_state[\"grad_norm_squared\"]\n",
        "    curv_win[self._iter % self._curv_win_width] = grad_norm_squared\n",
        "    valid_end = min(self._curv_win_width, self._iter + 1)\n",
        "    beta = self._beta\n",
        "    if self._iter == 0:\n",
        "      global_state[\"h_min_avg\"] = 0.0\n",
        "      global_state[\"h_max_avg\"] = 0.0\n",
        "      self._h_min = 0.0\n",
        "      self._h_max = 0.0\n",
        "    global_state[\"h_min_avg\"] = \\\n",
        "      global_state[\"h_min_avg\"] * beta + (1 - beta) * torch.min(curv_win[:valid_end] )\n",
        "    global_state[\"h_max_avg\"] = \\\n",
        "      global_state[\"h_max_avg\"] * beta + (1 - beta) * torch.max(curv_win[:valid_end] )\n",
        "    if self._zero_debias:\n",
        "      debias_factor = self.zero_debias_factor()\n",
        "      self._h_min = global_state[\"h_min_avg\"] / debias_factor\n",
        "      self._h_max = global_state[\"h_max_avg\"] / debias_factor\n",
        "    else:\n",
        "      self._h_min = global_state[\"h_min_avg\"]\n",
        "      self._h_max = global_state[\"h_max_avg\"]\n",
        "    return\n",
        "\n",
        "\n",
        "  def grad_variance(self):\n",
        "    global_state = self._global_state\n",
        "    beta = self._beta\n",
        "    self._grad_var = np.array(0.0, dtype=np.float32)\n",
        "    for group in self._optimizer.param_groups:\n",
        "      for p in group['params']:\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        grad = p.grad.data\n",
        "        state = self._optimizer.state[p]\n",
        "\n",
        "        if self._iter == 0:\n",
        "          state[\"grad_avg\"] = grad.new().resize_as_(grad).zero_()\n",
        "          state[\"grad_avg_squared\"] = 0.0\n",
        "        state[\"grad_avg\"].mul_(beta).add_(1 - beta, grad)\n",
        "        self._grad_var += torch.sum(state[\"grad_avg\"] * state[\"grad_avg\"] )\n",
        "        \n",
        "    if self._zero_debias:\n",
        "      debias_factor = self.zero_debias_factor()\n",
        "    else:\n",
        "      debias_factor = 1.0\n",
        "\n",
        "    self._grad_var /= -(debias_factor**2)\n",
        "    self._grad_var += global_state['grad_norm_squared_avg'] / debias_factor\n",
        "    return\n",
        "\n",
        "\n",
        "  def dist_to_opt(self):\n",
        "    global_state = self._global_state\n",
        "    beta = self._beta\n",
        "    if self._iter == 0:\n",
        "      global_state[\"grad_norm_avg\"] = 0.0\n",
        "      global_state[\"dist_to_opt_avg\"] = 0.0\n",
        "    global_state[\"grad_norm_avg\"] = \\\n",
        "      global_state[\"grad_norm_avg\"] * beta + (1 - beta) * math.sqrt(global_state[\"grad_norm_squared\"] )\n",
        "    global_state[\"dist_to_opt_avg\"] = \\\n",
        "      global_state[\"dist_to_opt_avg\"] * beta \\\n",
        "      + (1 - beta) * global_state[\"grad_norm_avg\"] / global_state['grad_norm_squared_avg']\n",
        "    if self._zero_debias:\n",
        "      debias_factor = self.zero_debias_factor()\n",
        "      self._dist_to_opt = global_state[\"dist_to_opt_avg\"] / debias_factor\n",
        "    else:\n",
        "      self._dist_to_opt = global_state[\"dist_to_opt_avg\"]\n",
        "    return\n",
        "\n",
        "\n",
        "  def after_apply(self):\n",
        "    # compute running average of gradient and norm of gradient\n",
        "    beta = self._beta\n",
        "    global_state = self._global_state\n",
        "    if self._iter == 0:\n",
        "      global_state[\"grad_norm_squared_avg\"] = 0.0\n",
        "\n",
        "    global_state[\"grad_norm_squared\"] = 0.0\n",
        "    for group in self._optimizer.param_groups:\n",
        "      for p in group['params']:\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        grad = p.grad.data\n",
        "        # global_state['grad_norm_squared'] += torch.dot(grad, grad)\n",
        "        global_state['grad_norm_squared'] += torch.sum(grad * grad)\n",
        "        \n",
        "    global_state['grad_norm_squared_avg'] = \\\n",
        "      global_state['grad_norm_squared_avg'] * beta + (1 - beta) * global_state['grad_norm_squared']\n",
        "    # global_state['grad_norm_squared_avg'].mul_(beta).add_(1 - beta, global_state['grad_norm_squared'] )\n",
        "        \n",
        "    self.curvature_range()\n",
        "    self.grad_variance()\n",
        "    self.dist_to_opt()\n",
        "    if self._iter > 0:\n",
        "      self.get_mu()    \n",
        "      self.get_lr()\n",
        "      self._lr = beta * self._lr + (1 - beta) * self._lr_t\n",
        "      self._mu = beta * self._mu + (1 - beta) * self._mu_t\n",
        "    return\n",
        "\n",
        "\n",
        "  def get_lr(self):\n",
        "    self._lr_t = (1.0 - math.sqrt(self._mu_t) )**2 / self._h_min\n",
        "    return\n",
        "\n",
        "\n",
        "  def get_mu(self):\n",
        "    coef = [-1.0, 3.0, 0.0, 1.0]\n",
        "    coef[2] = -(3 + self._dist_to_opt**2 * self._h_min**2 / 2 / self._grad_var)\n",
        "    roots = np.roots(coef)\n",
        "    root = roots[np.logical_and(np.logical_and(np.real(roots) > 0.0, \n",
        "      np.real(roots) < 1.0), np.imag(roots) < 1e-5) ]\n",
        "    assert root.size == 1\n",
        "    dr = self._h_max / self._h_min\n",
        "    self._mu_t = max(np.real(root)[0]**2, ( (np.sqrt(dr) - 1) / (np.sqrt(dr) + 1) )**2 )\n",
        "    return \n",
        "\n",
        "\n",
        "  def update_hyper_param(self):\n",
        "    for group in self._optimizer.param_groups:\n",
        "      group['momentum'] = self._mu\n",
        "      group['lr'] = self._lr * self._lr_factor\n",
        "    return\n",
        "\n",
        "\n",
        "  def step(self):\n",
        "    # add weight decay\n",
        "    for group in self._optimizer.param_groups:\n",
        "      for p in group['params']:\n",
        "        if p.grad is None:\n",
        "            continue\n",
        "        grad = p.grad.data\n",
        "\n",
        "        if group['weight_decay'] != 0:\n",
        "            grad = grad.add(group['weight_decay'], p.data)\n",
        "    \n",
        "    #if self._clip_thresh != None:\n",
        "    #  torch.nn.utils.clip_grad_norm(self._var_list, self._clip_thresh)\n",
        "    if self._clip_thresh is not None:\n",
        "      if isinstance(self._var_list[0], dict):\n",
        "        params = []\n",
        "        for p in self._var_list:\n",
        "          params.extend(p['params'])\n",
        "        torch.nn.utils.clip_grad_norm(params, self._clip_thresh)\n",
        "      else:\n",
        "        torch.nn.utils.clip_grad_norm(self._var_list, self._clip_thresh)\n",
        "    \n",
        "    # apply update\n",
        "    self._optimizer.step()\n",
        "\n",
        "    # after appply\n",
        "    self.after_apply()\n",
        "\n",
        "    # update learning rate and momentum\n",
        "    self.update_hyper_param()\n",
        "\n",
        "    self._iter += 1\n",
        "    return \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qFAP9A5mOAlw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn\n",
        "from sklearn.metrics import fbeta_score\n",
        "import shutil\n",
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def calc_crop_size(target_w, target_h, angle=0.0, scale=1.0):\n",
        "    crop_w = target_w\n",
        "    crop_h = target_h\n",
        "    if angle:\n",
        "        corners = np.array(\n",
        "            [[target_w/2, -target_w/2, -target_w/2, target_w/2],\n",
        "            [target_h/2, target_h/2, -target_h/2, -target_h/2]])\n",
        "        s = np.sin(angle * np.pi/180)\n",
        "        c = np.cos(angle * np.pi/180)\n",
        "        M = np.array([[c, -s], [s, c]])\n",
        "        rotated_corners = np.dot(M, corners)\n",
        "        crop_w = 2 * np.max(np.abs(rotated_corners[0, :]))\n",
        "        crop_h = 2 * np.max(np.abs(rotated_corners[1, :]))\n",
        "    crop_w = int(np.ceil(crop_w / scale))\n",
        "    crop_h = int(np.ceil(crop_h / scale))\n",
        "    return crop_w, crop_h\n",
        "\n",
        "\n",
        "def crop_center(img, cx, cy, crop_w, crop_h):\n",
        "    img_h, img_w = img.shape[:2]\n",
        "    trunc_top = trunc_bottom = trunc_left = trunc_right = 0\n",
        "    left = cx - crop_w//2\n",
        "    if left < 0:\n",
        "        trunc_left = 0 - left\n",
        "        left = 0\n",
        "    right = left - trunc_left + crop_w\n",
        "    if right > img_w:\n",
        "        trunc_right = right - img_w\n",
        "        right = img_w\n",
        "    top = cy - crop_h//2\n",
        "    if top < 0:\n",
        "        trunc_top = 0 - top\n",
        "        top = 0\n",
        "    bottom = top - trunc_top + crop_h\n",
        "    if bottom > img_h:\n",
        "        trunc_bottom = bottom - img_h\n",
        "        bottom = img_h\n",
        "    if trunc_left or trunc_right or trunc_top or trunc_bottom:\n",
        "        img_new = np.zeros((crop_h, crop_w, img.shape[2]), dtype=img.dtype)\n",
        "        trunc_bottom = crop_h - trunc_bottom\n",
        "        trunc_right = crop_w - trunc_right\n",
        "        img_new[trunc_top:trunc_bottom, trunc_left:trunc_right] = img[top:bottom, left:right]\n",
        "        return img_new\n",
        "    else:\n",
        "        return img[top:bottom, left:right]\n",
        "\n",
        "\n",
        "def crop_points_center(points, cx, cy, crop_w, crop_h):\n",
        "    xl = cx - crop_w // 2\n",
        "    xu = xl + crop_w\n",
        "    yl = cy - crop_h // 2\n",
        "    yu = yl + crop_h\n",
        "    mask = (points[:, 0] >= xl) & (points[:, 0] < xu) & (points[:, 1] >= yl) & (points[:, 1] < yu)\n",
        "    return points[mask]\n",
        "\n",
        "\n",
        "def crop_points(points, x, y, crop_w, crop_h):\n",
        "    xu = x + crop_w\n",
        "    yu = y + crop_h\n",
        "    mask = (points[:, 0] >= x) & (points[:, 0] < xu) & (points[:, 1] >= y) & (points[:, 1] < yu)\n",
        "    return points[mask]\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, initial_lr, decay_epochs=30):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    if isinstance(optimizer, YFOptimizer):\n",
        "        return\n",
        "    lr = initial_lr * (0.1 ** (epoch // decay_epochs))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar', output_dir=''):\n",
        "    save_path = os.path.join(output_dir, filename)\n",
        "    torch.save(state, save_path)\n",
        "    if is_best:\n",
        "        shutil.copyfile(save_path, os.path.join(output_dir, 'model_best.pth.tar'))\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "def scores(output, target, threshold=0.2):\n",
        "    # Count true positives, true negatives, false positives and false negatives.\n",
        "    outputr = (output > threshold).long()\n",
        "    target = target.long()\n",
        "    a_sum = 0.0\n",
        "    p_sum = 0.0\n",
        "    r_sum = 0.0\n",
        "    f2_sum = 0.0\n",
        "\n",
        "    def _safe_size(t, n=0):\n",
        "        if n < len(t.size()):\n",
        "            return t.size(n)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    count = 0\n",
        "    for o, t in zip(outputr, target):\n",
        "        tp = _safe_size(torch.nonzero(o * t))\n",
        "        tn = _safe_size(torch.nonzero((o - 1) * (t - 1)))\n",
        "        fp = _safe_size(torch.nonzero(o * (t - 1)))\n",
        "        fn = _safe_size(torch.nonzero((o - 1) * t))\n",
        "        a = (tp + tn) / (tp + fp + fn + tn)\n",
        "        if tp == 0 and fp == 0 and fn == 0:\n",
        "            p = 1.0\n",
        "            r = 1.0\n",
        "            f2 = 1.0\n",
        "        elif tp == 0 and (fp > 0 or fn > 0):\n",
        "            p = 0.0\n",
        "            r = 0.0\n",
        "            f2 = 0.0\n",
        "        else:\n",
        "            p = tp / (tp + fp)\n",
        "            r = tp / (tp + fn)\n",
        "            f2 = (5 * p * r) / (4 * p + r)\n",
        "        a_sum += a\n",
        "        p_sum += p\n",
        "        r_sum += r\n",
        "        f2_sum += f2\n",
        "        count += 1\n",
        "    accuracy = a_sum / count\n",
        "    precision = p_sum / count\n",
        "    recall = r_sum / count\n",
        "    fmeasure = f2_sum / count\n",
        "    return accuracy, precision, recall, fmeasure\n",
        "\n",
        "\n",
        "def f2_score(output, target, threshold):\n",
        "    output = (output > threshold)\n",
        "    return fbeta_score(target, output, beta=2, average='samples')\n",
        "\n",
        "\n",
        "def optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n",
        "    \"\"\" Find optimal threshold values for f2 score. Thanks Anokas\n",
        "    https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/32475\n",
        "    \"\"\"\n",
        "    size = y.shape[1]\n",
        "\n",
        "    def mf(x):\n",
        "        p2 = np.zeros_like(p)\n",
        "        for i in range(size):\n",
        "            p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n",
        "        score = fbeta_score(y, p2, beta=2, average='samples')\n",
        "        return score\n",
        "\n",
        "    x = [0.2] * size\n",
        "    for i in range(size):\n",
        "        best_i2 = 0\n",
        "        best_score = 0\n",
        "        for i2 in range(resolution):\n",
        "            i2 /= resolution\n",
        "            x[i] = i2\n",
        "            score = mf(x)\n",
        "            if score > best_score:\n",
        "                best_i2 = i2\n",
        "                best_score = score\n",
        "        x[i] = best_i2\n",
        "        if verbose:\n",
        "            print(i, best_i2, best_score)\n",
        "\n",
        "    return x, best_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EBU_hLrGOLfy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loss"
      ]
    },
    {
      "metadata": {
        "id": "3sanJ7ehOQUX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma: float = 2):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if target.size() != input.size():\n",
        "            raise ValueError(f'Target size ({target.size()}) must be the same as input size ({input.size()})')\n",
        "\n",
        "        input = input.float()\n",
        "        target = target.float()\n",
        "\n",
        "        max_val = (-input).clamp(min=0)\n",
        "        loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n",
        "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
        "        loss = (invprobs * self.gamma).exp() * loss\n",
        "\n",
        "        return loss.sum(dim=1).mean()\n",
        "\n",
        "\n",
        "class BCEWithLogitsLoss(nn.Module):\n",
        "    def __init__(self, weight=None):\n",
        "        super().__init__()\n",
        "        self.loss = nn.BCEWithLogitsLoss(weight)\n",
        "\n",
        "    def forward(self, y_pred, y):\n",
        "        return self.loss(y_pred.float(), y.float())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ohxEKF0eOvi9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ]
    },
    {
      "metadata": {
        "id": "4MnezIuUOyBO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn\n",
        "from sklearn.metrics import fbeta_score\n",
        "import shutil\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def calc_crop_size(target_w, target_h, angle=0.0, scale=1.0):\n",
        "    crop_w = target_w\n",
        "    crop_h = target_h\n",
        "    if angle:\n",
        "        corners = np.array(\n",
        "            [[target_w/2, -target_w/2, -target_w/2, target_w/2],\n",
        "            [target_h/2, target_h/2, -target_h/2, -target_h/2]])\n",
        "        s = np.sin(angle * np.pi/180)\n",
        "        c = np.cos(angle * np.pi/180)\n",
        "        M = np.array([[c, -s], [s, c]])\n",
        "        rotated_corners = np.dot(M, corners)\n",
        "        crop_w = 2 * np.max(np.abs(rotated_corners[0, :]))\n",
        "        crop_h = 2 * np.max(np.abs(rotated_corners[1, :]))\n",
        "    crop_w = int(np.ceil(crop_w / scale))\n",
        "    crop_h = int(np.ceil(crop_h / scale))\n",
        "    return crop_w, crop_h\n",
        "\n",
        "\n",
        "def crop_center(img, cx, cy, crop_w, crop_h):\n",
        "    img_h, img_w = img.shape[:2]\n",
        "    trunc_top = trunc_bottom = trunc_left = trunc_right = 0\n",
        "    left = cx - crop_w//2\n",
        "    if left < 0:\n",
        "        trunc_left = 0 - left\n",
        "        left = 0\n",
        "    right = left - trunc_left + crop_w\n",
        "    if right > img_w:\n",
        "        trunc_right = right - img_w\n",
        "        right = img_w\n",
        "    top = cy - crop_h//2\n",
        "    if top < 0:\n",
        "        trunc_top = 0 - top\n",
        "        top = 0\n",
        "    bottom = top - trunc_top + crop_h\n",
        "    if bottom > img_h:\n",
        "        trunc_bottom = bottom - img_h\n",
        "        bottom = img_h\n",
        "    if trunc_left or trunc_right or trunc_top or trunc_bottom:\n",
        "        img_new = np.zeros((crop_h, crop_w, img.shape[2]), dtype=img.dtype)\n",
        "        trunc_bottom = crop_h - trunc_bottom\n",
        "        trunc_right = crop_w - trunc_right\n",
        "        img_new[trunc_top:trunc_bottom, trunc_left:trunc_right] = img[top:bottom, left:right]\n",
        "        return img_new\n",
        "    else:\n",
        "        return img[top:bottom, left:right]\n",
        "\n",
        "\n",
        "def crop_points_center(points, cx, cy, crop_w, crop_h):\n",
        "    xl = cx - crop_w // 2\n",
        "    xu = xl + crop_w\n",
        "    yl = cy - crop_h // 2\n",
        "    yu = yl + crop_h\n",
        "    mask = (points[:, 0] >= xl) & (points[:, 0] < xu) & (points[:, 1] >= yl) & (points[:, 1] < yu)\n",
        "    return points[mask]\n",
        "\n",
        "\n",
        "def crop_points(points, x, y, crop_w, crop_h):\n",
        "    xu = x + crop_w\n",
        "    yu = y + crop_h\n",
        "    mask = (points[:, 0] >= x) & (points[:, 0] < xu) & (points[:, 1] >= y) & (points[:, 1] < yu)\n",
        "    return points[mask]\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, initial_lr, decay_epochs=30):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    if isinstance(optimizer, YFOptimizer):\n",
        "        return\n",
        "    lr = initial_lr * (0.1 ** (epoch // decay_epochs))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar', output_dir=''):\n",
        "    save_path = os.path.join(output_dir, filename)\n",
        "    torch.save(state, save_path)\n",
        "    if is_best:\n",
        "        shutil.copyfile(save_path, os.path.join(output_dir, 'model_best.pth.tar'))\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "def scores(output, target, threshold=0.2):\n",
        "    # Count true positives, true negatives, false positives and false negatives.\n",
        "    outputr = (output > threshold).long()\n",
        "    target = target.long()\n",
        "    a_sum = 0.0\n",
        "    p_sum = 0.0\n",
        "    r_sum = 0.0\n",
        "    f2_sum = 0.0\n",
        "\n",
        "    def _safe_size(t, n=0):\n",
        "        if n < len(t.size()):\n",
        "            return t.size(n)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    count = 0\n",
        "    for o, t in zip(outputr, target):\n",
        "        tp = _safe_size(torch.nonzero(o * t))\n",
        "        tn = _safe_size(torch.nonzero((o - 1) * (t - 1)))\n",
        "        fp = _safe_size(torch.nonzero(o * (t - 1)))\n",
        "        fn = _safe_size(torch.nonzero((o - 1) * t))\n",
        "        a = (tp + tn) / (tp + fp + fn + tn)\n",
        "        if tp == 0 and fp == 0 and fn == 0:\n",
        "            p = 1.0\n",
        "            r = 1.0\n",
        "            f2 = 1.0\n",
        "        elif tp == 0 and (fp > 0 or fn > 0):\n",
        "            p = 0.0\n",
        "            r = 0.0\n",
        "            f2 = 0.0\n",
        "        else:\n",
        "            p = tp / (tp + fp)\n",
        "            r = tp / (tp + fn)\n",
        "            f2 = (5 * p * r) / (4 * p + r)\n",
        "        a_sum += a\n",
        "        p_sum += p\n",
        "        r_sum += r\n",
        "        f2_sum += f2\n",
        "        count += 1\n",
        "    accuracy = a_sum / count\n",
        "    precision = p_sum / count\n",
        "    recall = r_sum / count\n",
        "    fmeasure = f2_sum / count\n",
        "    return accuracy, precision, recall, fmeasure\n",
        "\n",
        "\n",
        "def f2_score(output, target, threshold):\n",
        "    output = (output > threshold)\n",
        "    return fbeta_score(target, output, beta=2, average='samples')\n",
        "\n",
        "\n",
        "def optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n",
        "    \"\"\" Find optimal threshold values for f2 score. Thanks Anokas\n",
        "    https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/32475\n",
        "    \"\"\"\n",
        "    size = y.shape[1]\n",
        "\n",
        "    def mf(x):\n",
        "        p2 = np.zeros_like(p)\n",
        "        for i in range(size):\n",
        "            p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n",
        "        score = fbeta_score(y, p2, beta=2, average='samples')\n",
        "        return score\n",
        "\n",
        "    x = [0.2] * size\n",
        "    for i in range(size):\n",
        "        best_i2 = 0\n",
        "        best_score = 0\n",
        "        for i2 in range(resolution):\n",
        "            i2 /= resolution\n",
        "            x[i] = i2\n",
        "            score = mf(x)\n",
        "            if score > best_score:\n",
        "                best_i2 = i2\n",
        "                best_score = score\n",
        "        x[i] = best_i2\n",
        "        if verbose:\n",
        "            print(i, best_i2, best_score)\n",
        "\n",
        "    return x, best_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JV8AJXxAPBiy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "id": "N4jwDF3_PEXn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data.sampler import Sampler\n",
        "from typing import Tuple, List, Any\n",
        "import albumentations as album\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "#BASE_PATH = 'C:\\\\Kaggle\\\\atlas\\\\rwightman\\\\data'\n",
        "#TRAIN_CSV = 'train.csv'\n",
        "\n",
        "IMG_EXTENSIONS = [ '.png']\n",
        "LABELS = list(map(str,range(28)))\n",
        "\"\"\"\n",
        "def create_class_weight(labels_dict, mu=0.8):\n",
        "  total = sum(labels_dict.values())\n",
        "  keys = labels_dict.keys()\n",
        "  class_weight = dict()\n",
        "  class_weight_log = dict()\n",
        "\n",
        "  for key in keys:\n",
        "      score = total / float(labels_dict[key])\n",
        "      score_log = math.log(mu * total / float(labels_dict[key]))\n",
        "      class_weight[key] = round(score, 2) if score > 1.0 else round(1.0, 2)\n",
        "      class_weight_log[key] = round(score_log, 2) if score_log > 1.0 else round(1.0, 2)\n",
        "  return class_weight, class_weight_log\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(BASE_PATH,TRAIN_CSV))\n",
        "train_df.Target = train_df.Target.map(lambda x: set(x.split()))\n",
        "count = Counter()\n",
        "train_df.Target.apply(lambda x: count.update(x))\n",
        "labels_dict=dict(count)\n",
        "true_class_weights=create_class_weight(labels_dict)[0]\n",
        "log_class_weights=create_class_weight(labels_dict)[1]\n",
        "\n",
        "ALL_WEIGHTS=[true_class_weights[key] for key in sorted(true_class_weights.keys(), \n",
        "             key=lambda x:int(x))]\n",
        "    \n",
        "ALL_WEIGHTS_L=[log_class_weights[key] for key in sorted(log_class_weights.keys(), \n",
        "             key=lambda x:int(x))]\n",
        "\"\"\"   \n",
        "ALL_WEIGHTS = [3.94, 40.5, 14.02, 32.53, 27.33, 20.21, 50.38, 18.0, 958.15, \n",
        "               1128.49, 1813.64, 46.46, 73.81, 94.57, 47.64, 2418.19, 95.82, \n",
        "               241.82, 56.3, 34.27, 295.24, 13.45, 63.32, 17.13, 157.71, 6.17, \n",
        "               154.82, 4616.55]\n",
        "\n",
        "ALL_WEIGHTS_L = [1.15, 3.48, 2.42, 3.26, 3.08, 2.78, 3.7, 2.67, 6.64, 6.81, \n",
        "                 7.28, 3.62, 4.08, 4.33, 3.64, 7.57, 4.34, 5.27, 3.81, 3.31, \n",
        "                 5.46, 2.38, 3.93, 2.62, 4.84, 1.6, 4.82, 8.21]\n",
        "\n",
        "\n",
        "def find_inputs(folder, types=IMG_EXTENSIONS):\n",
        "    inputs = []\n",
        "    for root, _, files in os.walk(folder, topdown=False):\n",
        "        for rel_filename in files:\n",
        "            base, ext = os.path.splitext(rel_filename)\n",
        "            if ext.lower() in types:\n",
        "                abs_filename = os.path.join(root, rel_filename)\n",
        "                inputs.append((base, abs_filename))\n",
        "    return inputs\n",
        "\n",
        "def get_test_aug(factor):\n",
        "    if not factor or factor == 1:\n",
        "        return [\n",
        "            [False, False, False]]\n",
        "    elif factor == 4:\n",
        "        # transpose, v-flip, h-flip\n",
        "        return [\n",
        "            [False, False, False],\n",
        "            [False, False, True],\n",
        "            [False, True, False],\n",
        "            [True, True, True]]\n",
        "    elif factor == 8:\n",
        "        # return list of all combinations of flips and transpose\n",
        "        return ((1 & np.arange(0, 8)[:, np.newaxis] // 2**np.arange(2, -1, -1)) > 0).tolist()\n",
        "    else:\n",
        "        print('Invalid augmentation factor')\n",
        "        return [\n",
        "            [False, False, False]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UyqEsrc5ReWL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HumanDataset(data.Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_root,\n",
        "            target_file='',\n",
        "            train=True,\n",
        "            img_size=512,\n",
        "            fold=0,\n",
        "            test_aug=0,\n",
        "            num_channels=3,\n",
        "            transform=None):\n",
        "\n",
        "        inputs = find_inputs(input_root)\n",
        "        if len(inputs) == 0:\n",
        "            raise (RuntimeError(\"Found 0 images in : \" + input_root))\n",
        "        target_df = pd.read_csv(target_file)\n",
        "        if train:\n",
        "            target_df = target_df[target_df['fold'] != fold]\n",
        "        else:\n",
        "            target_df = target_df[target_df['fold'] == fold]\n",
        "        target_df.drop(['fold'], 1, inplace=True)\n",
        "\n",
        "        self.inputs = target_df['Id'].apply(lambda x:os.path.join(input_root,x)).tolist()\n",
        "        self.target_array = target_df.as_matrix(columns=LABELS).astype(np.float32)\n",
        "        self.target_array = torch.from_numpy(self.target_array)\n",
        "        self.train = train\n",
        "        self.dataset_mean = [0.0804419, 0.05262986, 0.05474701] \n",
        "        self.dataset_std = [0.13000701, 0.08796628, 0.1386317] \n",
        "        self.img_size = img_size\n",
        "        self.my_transform = transform\n",
        "        if not train:\n",
        "            self.test_aug = get_test_aug(test_aug)\n",
        "        else:\n",
        "            self.test_aug = []\n",
        "\n",
        "\n",
        "    def _load_input(self, index):\n",
        "        path = self.inputs[index]\n",
        "        colors = ['red','green','blue']\n",
        "        flags = cv2.IMREAD_GRAYSCALE\n",
        "        img = [cv2.imread((path+'_'+color+'.png'), flags) for color in colors]\n",
        "        return np.stack(img, axis=-1) \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input_img = self._load_input(index)\n",
        "        if self.target_array is not None:\n",
        "            target_tensor = self.target_array[index]\n",
        "        else:\n",
        "            target_tensor = torch.zeros(1)\n",
        "        \n",
        "        augmented = self.my_transform(image=input_img)\n",
        "        input_tensor =  transforms.ToTensor()(augmented['image'])\n",
        "        index_tensor = torch.LongTensor([index])\n",
        "        return input_tensor, target_tensor, index_tensor\n",
        "       \n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.inputs) * len(self.test_aug) if self.test_aug else len(self.inputs)\n",
        "\n",
        "    def get_aug_factor(self):\n",
        "        return len(self.test_aug)\n",
        "\n",
        "    def get_class_weights(self):\n",
        "        return np.array(ALL_WEIGHTS_L)\n",
        "\n",
        "    def get_sample_weights(self):\n",
        "        class_weights = torch.FloatTensor(self.get_class_weights())\n",
        "        weighted_samples = []\n",
        "        for index in range(len(self.inputs)):\n",
        "            masked_weights = self.target_array[index] * class_weights\n",
        "            weighted_samples.append(masked_weights.max())\n",
        "        weighted_samples = torch.DoubleTensor(weighted_samples)\n",
        "        weighted_samples = weighted_samples / weighted_samples.min()\n",
        "        return weighted_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TzyBhtfVTjXa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class WeightedRandomOverSampler(Sampler):\n",
        "    #Over-samples elements from [0,..,len(weights)-1] factor number of times.\n",
        "    #Each element is sample at least once, the remaining over-sampling is determined\n",
        "    #by the weights.\n",
        "    #Arguments:\n",
        "    #    weights (list) : a list of weights, not necessary summing up to one\n",
        "    #    factor (float) : the oversampling factor (>= 1.0)\n",
        "   \n",
        "\n",
        "    def __init__(self, weights, factor=2.):\n",
        "        self.weights = torch.DoubleTensor(weights)\n",
        "        assert factor >= 1.\n",
        "        self.num_samples = int(len(self.weights) * factor)\n",
        "\n",
        "    def __iter__(self):\n",
        "        base_samples = torch.arange(0, len(self.weights)).long()\n",
        "        remaining = self.num_samples - len(self.weights)\n",
        "        over_samples = torch.multinomial(self.weights, remaining, True)\n",
        "        samples = torch.cat((base_samples, over_samples), dim=0)\n",
        "        print('num samples', len(samples))\n",
        "        return (samples[i] for i in torch.randperm(len(samples)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pC0E-tGJRb-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_transforms(image_size: int) -> Tuple[album.Compose, album.Compose, album.Compose]:\n",
        "    transforms_train = album.Compose([\n",
        "        album.Resize(image_size, image_size, interpolation=Image.BICUBIC),\n",
        "        album.Rotate(interpolation=Image.BICUBIC),\n",
        "        album.RandomRotate90(),\n",
        "        album.HorizontalFlip(),\n",
        "        album.RandomBrightnessContrast(),\n",
        "        album.Normalize([0.08069, 0.05258, 0.05487], [0.13704, 0.10145, 0.15313])\n",
        "    ])\n",
        "\n",
        "    transforms_test = album.Compose([\n",
        "        album.Resize(image_size, image_size, interpolation=Image.BICUBIC),\n",
        "        album.Normalize([0.08069, 0.05258, 0.05487], [0.13704, 0.10145, 0.15313])\n",
        "    ])\n",
        "\n",
        "    transforms_test_aug = album.Compose([\n",
        "        album.Resize(image_size, image_size, interpolation=Image.BICUBIC),\n",
        "        album.Rotate(interpolation=Image.BICUBIC),\n",
        "        album.RandomRotate90(),\n",
        "        album.HorizontalFlip(),\n",
        "        album.Normalize([0.08069, 0.05258, 0.05487], [0.13704, 0.10145, 0.15313])\n",
        "    ])\n",
        "\n",
        "    return transforms_train, transforms_test, transforms_test_aug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HJn6EmhMPtHP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train epoch"
      ]
    },
    {
      "metadata": {
        "id": "YwrbWha6PwyA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils\n",
        "\n",
        "def train_epoch(\n",
        "        epoch, model, loader, optimizer, loss_fn,\n",
        "        class_weights=None, output_dir='', exp=None, batch_limit=0):\n",
        "\n",
        "    epoch_step = (epoch - 1) * len(loader)\n",
        "    losses_m = AverageMeter()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (input, target, index) in enumerate(loader):\n",
        "        if not config.no_cuda:\n",
        "            input, target = input.cuda(), target.cuda()\n",
        "        input_var = autograd.Variable(input)\n",
        "        target_var = autograd.Variable(target)\n",
        "        output = model(input_var)\n",
        "\n",
        "        loss = loss_fn(output, target_var)\n",
        "        losses_m.update(loss.data.item(), input_var.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "                             \n",
        "        rowd = OrderedDict(batch_idx=batch_idx)\n",
        "        rowd.update(OrderedDict([('lr', optimizer.param_groups[0]['lr'])]))\n",
        "\n",
        "        with open(os.path.join(output_dir, 'summary_lr_%d.csv'%epoch), mode='a') as cf:\n",
        "          dw = csv.DictWriter(cf, fieldnames=rowd.keys())\n",
        "          dw.writerow(rowd)\n",
        "        with open(os.path.join('summary_lr_%d.csv'%epoch), mode='a') as local:\n",
        "          dw = csv.DictWriter(local, fieldnames=rowd.keys())\n",
        "          dw.writerow(rowd)\n",
        "          \n",
        "        if batch_idx % config.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]  '\n",
        "                  'Loss: {loss.val:.6f} ({loss.avg:.4f})  '.format(\n",
        "                epoch,\n",
        "                batch_idx * len(input), len(loader.sampler),\n",
        "                100. * batch_idx / len(loader),\n",
        "                loss=losses_m))\n",
        "        \n",
        "            \n",
        "            if exp is not None:\n",
        "                exp.add_scalar_value('loss_train', losses_m.val, step=step)\n",
        "                exp.add_scalar_value('learning_rate', optimizer.param_groups[0]['lr'], step=step)\n",
        "\n",
        "            if config.save_batches:\n",
        "                torchvision.utils.save_image(\n",
        "                    input,\n",
        "                    os.path.join(output_dir, 'train-batch-%d.jpg' % batch_idx),\n",
        "                    padding=0,\n",
        "                    normalize=True)\n",
        "\n",
        "        if batch_limit and batch_idx >= batch_limit:\n",
        "            break\n",
        "    return OrderedDict([('train_loss', losses_m.avg)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7Y0LD9HP8xr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate(step, model, loader, loss_fn,  threshold, output_dir='', exp=None):\n",
        "    batch_time_m = AverageMeter()\n",
        "    losses_m = AverageMeter()\n",
        "    prec1_m = AverageMeter()\n",
        "    acc_m = AverageMeter()\n",
        "    f2_m = AverageMeter()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    output_list = []\n",
        "    target_list = []\n",
        "    for i, (input, target, _) in enumerate(loader):\n",
        "        if not config.no_cuda:\n",
        "            input, target = input.cuda(), target.cuda()\n",
        "        target_var = autograd.Variable(target.max(dim=1)[1].squeeze(), volatile=True)\n",
        "        input_var = autograd.Variable(input, volatile=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "\n",
        "        # augmentation reduction\n",
        "        reduce_factor = loader.dataset.get_aug_factor()\n",
        "        if reduce_factor > 1:\n",
        "            output.data = output.data.unfold(0, reduce_factor, reduce_factor).mean(dim=2)\n",
        "            target_var.data = target_var.data[0:target_var.size(0):reduce_factor]\n",
        "\n",
        "        # calc loss\n",
        "        loss = loss_fn(output, target_var)\n",
        "        losses_m.update(loss.data.item(), input.size(0))\n",
        "\n",
        "        # output non-linearities and metrics\n",
        "\n",
        "        output = F.softmax(output)\n",
        "        a, p, _, f2 = scores(output.data, target_var.data, threshold)\n",
        "        acc_m.update(a, output.size(0))\n",
        "        prec1_m.update(p, output.size(0))\n",
        "        f2_m.update(f2, output.size(0))\n",
        "\n",
        "        # copy to CPU and collect\n",
        "        target_list.append(target.cpu().numpy())\n",
        "        output_list.append(output.data.cpu().numpy())\n",
        "\n",
        "        batch_time_m.update(time.time() - end)\n",
        "        end = time.time()\n",
        "        if i % config.print_freq == 0:\n",
        "            print('Test: [{0}/{1}]\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})  '\n",
        "                  'Acc {acc.val:.4f} ({acc.avg:.4f})  '\n",
        "                  'Prec {prec.val:.4f} ({prec.avg:.4f})  '\n",
        "                  'F2 {f2.val:.4f} ({f2.avg:.4f})  '.format(\n",
        "                    i, len(loader),\n",
        "                    loss=losses_m,\n",
        "                    acc=acc_m, prec=prec1_m, f2=f2_m))\n",
        " \n",
        "            if config.save_batches:\n",
        "                torchvision.utils.save_image(\n",
        "                    input,\n",
        "                    os.path.join(output_dir, 'validate-batch-%d.jpg' % i),\n",
        "                    padding=0,\n",
        "                    normalize=True)\n",
        "\n",
        "    output_total = np.concatenate(output_list, axis=0)\n",
        "    target_total = np.concatenate(target_list, axis=0)\n",
        "\n",
        "    new_threshold, f2 = optimise_f2_thresholds(target_total, output_total)\n",
        "    metrics = [('eval_loss', losses_m.avg), ('eval_f2', f2)]\n",
        "\n",
        "    print(f2, new_threshold)\n",
        "\n",
        " #   if exp is not None:\n",
        "#        exp.add_scalar_value('loss_eval', losses_m.avg, step=step)\n",
        "#        exp.add_scalar_value('prec@1_eval', prec1_m.avg, step=step)\n",
        "#        exp.add_scalar_value('f2_eval', f2, step=step)\n",
        "\n",
        "    return OrderedDict(metrics), new_threshold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t5kqM3A3_xpF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lxUsZraBQQqH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "d94QREHaQSFl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "import torchvision.models as models\n",
        "import pretrainedmodels\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class AdaptiveConcatPool2d(torch.nn.Module):\n",
        "    def __init__(self, sz: Tuple[int, int] = (1, 1)):\n",
        "        super().__init__()\n",
        "        self.average_pool = torch.nn.AdaptiveAvgPool2d(sz)\n",
        "        self.max_pool = torch.nn.AdaptiveMaxPool2d(sz)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([self.max_pool(x), self.average_pool(x)], 1)\n",
        "def freeze(model: torch.nn.Module):\n",
        "    \"\"\"Freeze all model parameters.\"\"\"\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "\n",
        "def unfreeze(model: torch.nn.Module):\n",
        "    \"\"\"Unfreeze all model parameters.\"\"\"\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tFOKMUNWQZnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_model(model_name: str, num_classes: int, pretrained: str):\n",
        "    return pretrainedmodels.__dict__[model_name](num_classes=num_classes, pretrained=pretrained)\n",
        "\n",
        "def get_model(model_name: str,\n",
        "              num_classes: int,\n",
        "              num_channels: int = 3,\n",
        "              dropout: float = 0.5,\n",
        "              frozen: bool = True):\n",
        "    model = load_model(model_name, num_classes=1000, pretrained='imagenet')\n",
        "\n",
        "    if frozen:\n",
        "        freeze(model)\n",
        "\n",
        "    if num_channels == 4:\n",
        "        w = model.conv1.weight\n",
        "        model.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        model.conv1.weight = nn.Parameter(torch.cat((w, w[:, 1:2, :, :]), dim=1))\n",
        "\n",
        "    model.avgpool = nn.Sequential(AdaptiveConcatPool2d())\n",
        "\n",
        "    model.last_linear = nn.Sequential(\n",
        "        nn.BatchNorm1d(4096),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(4096, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sKtj3JboPl0t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "v4nivp7DPn4v",
        "colab_type": "code",
        "outputId": "e24af500-f095-42fd-9df6-06e647bfe7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn\n",
        "import torch.optim as optim \n",
        "import torch.utils.data as data\n",
        "\n",
        "def main():\n",
        "    train_input_root = os.path.join(config.data_path,'train')\n",
        "    train_labels_file = config.target_file\n",
        "\n",
        "    if config.output_path:\n",
        "        output_base = config.output_path\n",
        "    else:\n",
        "        output_base = './output'\n",
        "\n",
        "    exp_name = '-'.join([config.exp,\n",
        "        config.model,\n",
        "        str(config.img_size),\n",
        "        'f'+str(config.fold)])\n",
        "    output_dir = os.path.join(output_base, 'train', exp_name)\n",
        "    if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "\n",
        "    batch_size = config.batch_size\n",
        "    num_epochs = config.epochs\n",
        "    img_size = config.img_size\n",
        "    transforms_train, transforms_test, transforms_test_aug = get_transforms(img_size)\n",
        "\n",
        "    torch.manual_seed(config.seed)\n",
        "\n",
        "    dataset_train = HumanDataset(\n",
        "        train_input_root,\n",
        "        train_labels_file,\n",
        "        train=True,\n",
        "        img_size=img_size,\n",
        "        fold=config.fold,\n",
        "        transform=transforms_train\n",
        "    )\n",
        "    sampler = WeightedRandomOverSampler(dataset_train.get_sample_weights())\n",
        "    loader_train = data.DataLoader(\n",
        "        dataset_train,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        sampler=sampler,\n",
        "        num_workers=1,\n",
        "        pin_memory=False\n",
        "    )\n",
        "    dataset_eval = HumanDataset(\n",
        "        train_input_root,\n",
        "        train_labels_file,\n",
        "        train=False,\n",
        "        img_size=img_size,\n",
        "        fold=config.fold,\n",
        "        transform=transforms_test\n",
        "    )\n",
        "\n",
        "    loader_eval = data.DataLoader(\n",
        "        dataset_eval,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=1,\n",
        "        pin_memory=False\n",
        "    )\n",
        "    model=get_model(config.model,config.num_classes,config.num_channels,config.dropout)\n",
        "    \n",
        "    if not config.no_cuda:\n",
        "        model.cuda()\n",
        "\n",
        "    if config.opt.lower() == 'sgd':\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(), lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay)\n",
        "    elif config.opt.lower() == 'adam':\n",
        "        optimizer = optim.Adam(\n",
        "            model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "    elif config.opt.lower() == 'adadelta':\n",
        "        optimizer = optim.Adadelta(\n",
        "            model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "    elif config.opt.lower() == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(\n",
        "            model.parameters(), lr=config.lr, alpha=0.9, momentum=config.momentum, \n",
        "            weight_decay=config.weight_decay)\n",
        "    elif config.opt.lower() == 'yellowfin':\n",
        "        optimizer = YFOptimizer(\n",
        "            model.parameters(), lr=config.lr, weight_decay=config.weight_decay, clip_thresh=2)\n",
        "    else:\n",
        "        assert False and \"Invalid optimizer\"\n",
        "\n",
        "    if not config.decay_epochs:\n",
        "        lr_scheduler = ReduceLROnPlateau(optimizer, patience=8)\n",
        "    else:\n",
        "        lr_scheduler = None\n",
        "\n",
        "    if config.class_weights:\n",
        "        class_weights = torch.from_numpy(dataset_train.get_class_weights()).float()\n",
        "        class_weights_norm = class_weights / class_weights.sum()\n",
        "        if not config.no_cuda:\n",
        "            class_weights = class_weights.cuda()\n",
        "            class_weights_norm = class_weights_norm.cuda()\n",
        "    else:\n",
        "        class_weights = None\n",
        "        class_weights_norm = None\n",
        "    \n",
        "    if config.loss.lower() == 'bce':\n",
        "        #assert not args.multi_label and 'Cannot use crossentropy with multi-label target.'\n",
        "        loss_fn = BCEWithLogitsLoss(weight=class_weights)\n",
        "    elif config.loss.lower() == 'focal':\n",
        "        loss_fn =FocalLoss()\n",
        "    else:\n",
        "        assert False and \"Invalid loss function\"\n",
        "    if not config.no_cuda:\n",
        "        loss_fn = loss_fn.cuda()\n",
        "\n",
        "    start_epoch = 1\n",
        "\n",
        "        \n",
        "    if config.checkpoint:\n",
        "        if os.path.isfile(config.checkpoint):\n",
        "            print(\"=> loading checkpoint '{}'\".format(config.checkpoint))\n",
        "            checkpoint = torch.load(config.checkpoint)   \n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\".format(config.checkpoint, checkpoint['epoch']))\n",
        "            start_epoch = checkpoint['epoch']\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(config.checkpoint))\n",
        "            exit(-1)\n",
        "    # Optional fine-tune of only the final classifier weights for specified number of epochs (or part of)\n",
        "    if not config.checkpoint and config.ft_epochs > 0.:\n",
        "        if config.opt.lower() == 'adam':\n",
        "            finetune_optimizer = optim.Adam(\n",
        "                model.get_fc().parameters(), lr=config.ft_lr, weight_decay=config.weight_decay)\n",
        "        else:\n",
        "            finetune_optimizer = optim.SGD(\n",
        "                model.get_fc().parameters(), lr=config.ft_lr, momentum=config.momentum, weight_decay=config.weight_decay)\n",
        "\n",
        "        finetune_epochs_int = int(np.ceil(config.ft_epochs))\n",
        "        finetune_final_batches = int(np.ceil((1 - (finetune_epochs_int - config.ft_epochs)) * len(loader_train)))\n",
        "        print(finetune_epochs_int, finetune_final_batches)\n",
        "        for fepoch in range(1, finetune_epochs_int + 1):\n",
        "            if fepoch == finetune_epochs_int and finetune_final_batches:\n",
        "                batch_limit = finetune_final_batches\n",
        "            else:\n",
        "                batch_limit = 0\n",
        "            train_epoch(\n",
        "                fepoch, model, loader_train, finetune_optimizer, loss_fn, \n",
        "                class_weights_norm, output_dir, batch_limit=batch_limit)\n",
        "            step = fepoch * len(loader_train)\n",
        "            score, _ = validate(step, model, loader_eval, loss_fn,  0.2, output_dir)\n",
        "            \n",
        "    score_metric = 'f2'\n",
        "    best_loss = None\n",
        "    best_f2 = None\n",
        "    threshold = 0.2\n",
        "    try:\n",
        "        for epoch in range(start_epoch, num_epochs + 1):\n",
        "            if config.decay_epochs:\n",
        "                adjust_learning_rate(optimizer, epoch, initial_lr=config.lr, decay_epochs=config.decay_epochs)\n",
        "                \n",
        "            train_metrics = train_epoch(\n",
        "                epoch, model, loader_train, optimizer, loss_fn, class_weights_norm, output_dir, exp=None)\n",
        "            \n",
        "            step = epoch * len(loader_train)\n",
        "            eval_metrics, latest_threshold = validate(\n",
        "                step, model, loader_eval, loss_fn,  threshold, output_dir, exp=None)\n",
        "\n",
        "            if lr_scheduler is not None:\n",
        "                lr_scheduler.step(eval_metrics['eval_loss'])\n",
        "\n",
        "            rowd = OrderedDict(epoch=epoch)\n",
        "            rowd.update(train_metrics)\n",
        "            rowd.update(eval_metrics)\n",
        "            with open(os.path.join(output_dir, 'summary.csv'), mode='a') as cf:\n",
        "                dw = csv.DictWriter(cf, fieldnames=rowd.keys())\n",
        "                if best_loss is None:  # first iteration (epoch == 1 can't be used)\n",
        "                    dw.writeheader()\n",
        "                dw.writerow(rowd)\n",
        "\n",
        "            best = False\n",
        "            if best_loss is None or eval_metrics['eval_loss'] < best_loss[1]:\n",
        "                best_loss = (epoch, eval_metrics['eval_loss'])\n",
        "                if score_metric == 'loss':\n",
        "                    best = True\n",
        "            if best_f2 is None or eval_metrics['eval_f2'] > best_f2[1]:\n",
        "                best_f2 = (epoch, eval_metrics['eval_f2'])\n",
        "                if score_metric == 'f2':\n",
        "                    best = True\n",
        "\n",
        "            save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'arch': config.model,\n",
        "                'state_dict':  model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'threshold': latest_threshold,\n",
        "                },\n",
        "                is_best=best,\n",
        "                filename='checkpoint-%d.pth.tar' % epoch,\n",
        "                output_dir=output_dir)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "      print('*** Best loss: {0} (epoch {1})'.format(best_loss[1], best_loss[0]))\n",
        "      print('*** Best f2: {0} (epoch {1})'.format(best_f2[1], best_f2[0]))           \n",
        "            \n",
        "            \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples 49528\n",
            "Train Epoch: 1 [0/49528 (0%)]  Loss: 2.965889 (2.9659)  \n",
            "Train Epoch: 1 [8000/49528 (16%)]  Loss: 0.694512 (1.7479)  \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}